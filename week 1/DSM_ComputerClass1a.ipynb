{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Class 1a - pandas and data aggregation\n",
    "\n",
    "The examples and exercises of this computer class introduce the student to working with the pandas library. It can be used in conjunction with chapters 5-8 and 10 of the McKinney book.\n",
    "\n",
    "*Authors: Cees Diks and Bram Wouters, Faculty Economics and Business, University of Amsterdam (UvA)* <br>\n",
    "*Copyright (C): UvA (2023)* <br>\n",
    "*Credits: some of the examples and formulations are taken from McKinney.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating a Series and Series basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** create a Series with indices 'United States', 'Netherlands', 'Australia','Uruguay' and values 'North America', 'Europe', 'Oceania', 'South America', respectively. Call the Series `ser1` and show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    North America\n",
       "Netherlands             Europe\n",
       "Australia              Oceania\n",
       "Uruguay          South America\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series(['North America', 'Europe', 'Oceania', 'South America'], index=[\"United States\", 'Netherlands', 'Australia','Uruguay'])\n",
    "ser1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** use a dictionary to create a second Series (called `ser2`) with indices 'Netherlands','China','France' and values 'Europe', 'Asia', respectively. The value corresponding to the index 'France' is missing on purpose and Python reports it as NaN (Not a Number). Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Netherlands    Europe\n",
       "China            Asia\n",
       "France            NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"Netherlands\": \"Europe\", \"China\": \"Asia\"}\n",
    "ser2 = pd.Series(d, index=[\"Netherlands\", \"China\", \"France\"])\n",
    "ser2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** use the pandas function `concat` to merge `ser1` and `ser2`. Call the resulting Series `ser3` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    North America\n",
       "Netherlands             Europe\n",
       "Australia              Oceania\n",
       "Uruguay          South America\n",
       "Netherlands             Europe\n",
       "China                     Asia\n",
       "France                     NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser3 = pd.concat([ser1, ser2])\n",
    "ser3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** remove the duplicated data from `ser3`. Note that instead of redefining `ser3`, you can also use the `inplace` keyword. Print the resulting `ser3`. (Hint: use the Series method `drop_duplicates`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    North America\n",
       "Netherlands             Europe\n",
       "Australia              Oceania\n",
       "Uruguay          South America\n",
       "China                     Asia\n",
       "France                     NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser3.drop_duplicates(inplace=True)\n",
    "ser3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** create a boolean that checks whether there are any missing values (NaN) in `ser3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States    False\n",
       "Netherlands      False\n",
       "Australia        False\n",
       "Uruguay          False\n",
       "China            False\n",
       "France            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser3.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** replace the missing value in `ser3` by the correct continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser3.fillna(\"Europe\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** a Series and the index of a Series both have a name attribute. This can be useful when dealing with many different Series and/or when multiple people need to work with the same Series. Give `ser3` the following name: 'continent'. Also, give the index of `ser3` the name 'country' and print the resulting `ser3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Countries\n",
       "United States    North America\n",
       "Netherlands             Europe\n",
       "Australia              Oceania\n",
       "Uruguay          South America\n",
       "China                     Asia\n",
       "France                  Europe\n",
       "Name: Continents, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser3.name = \"Continents\"\n",
    "ser3.index.name = \"Countries\"\n",
    "ser3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a DataFrame and DataFrame basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** create DataFrame that corresponds to the table below and bind the variable `df1` to it. The first column in the table below should serve as index of the DataFrame. Make sure the column indices match the column names of the table. Show the resulting `df1` as output.\n",
    "\n",
    "|**country**|**GDP (nominal, \\$MM)**| **population (MM)**|\n",
    "|:-------|:-------------|:--------|\n",
    "| **United States**        |    20412870          |    327.4     |\n",
    "| **France**        |    2925096          |    67.2     |\n",
    "| **Netherlands**        |   945327          |    17.2     |\n",
    "| **Australia**        |    1500256          |    25.0     |\n",
    "| **Uruguay**        |    63370          |    3.5     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)\n",
       "country                                           \n",
       "United States          20412870.0            327.4\n",
       "France                  2925096.0             67.2\n",
       "Netherlands              945327.0             17.2\n",
       "Australia               1500256.0             25.0\n",
       "Uruguay                   63370.0              3.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"United States\": [20412870, 327.4], \"France\": [2925096, 67.2], \"Netherlands\": [945327, 17.2], \"Australia\": [1500256, 25.0], \"Uruguay\": [63370, 3.5]}\n",
    "df1 = pd.DataFrame(d, index=[\"GDP (nominal, $MM)\", \"population (MM)\"]).T\n",
    "df1.index.name = \"country\"\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** use square brackets `[]` to extract the population column from the DataFrame and print it. Also, verify explicitely that this column is a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "United States    327.4\n",
       "France            67.2\n",
       "Netherlands       17.2\n",
       "Australia         25.0\n",
       "Uruguay            3.5\n",
       "Name: population (MM), dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = df1[\"population (MM)\"]\n",
    "assert isinstance(pop, pd.Series)\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** add `ser3` as an extra column to `df1` and call the new DataFrame `df2`. Make sure that China is included as a row in `df2`. (Hint: turn `ser3` into a DataFrame with the method `to_frame` and subsequently use `merge`. Use the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) to find out which keywords you need.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents\n",
       "Australia               1500256.0             25.0        Oceania\n",
       "China                         NaN              NaN           Asia\n",
       "France                  2925096.0             67.2         Europe\n",
       "Netherlands              945327.0             17.2         Europe\n",
       "United States          20412870.0            327.4  North America\n",
       "Uruguay                   63370.0              3.5  South America"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.merge(ser3.to_frame(), right_index=True, left_index=True, how=\"outer\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** replace the missing values for China by the actual values. (Note: use `at[...]` for accessing values of a DataFrame. Don't use `get_value`; this is an old method that will be discarded in future versions of pandas.) Also note that for indexing one can use both index/column names and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents\n",
       "Australia               1500256.0             25.0        Oceania\n",
       "China                  17960000.0           1409.7           Asia\n",
       "France                  2925096.0             67.2         Europe\n",
       "Netherlands              945327.0             17.2         Europe\n",
       "United States          20412870.0            327.4  North America\n",
       "Uruguay                   63370.0              3.5  South America"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.at[\"China\", \"GDP (nominal, $MM)\"] = 17960000\n",
    "df2.at[\"China\", \"population (MM)\"] = 1409.7\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** add another column called 'visited?' to `df2`. The values must be booleans and indicate whether or not you have visited the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>South America</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents  visited\n",
       "Australia               1500256.0             25.0        Oceania    False\n",
       "China                  17960000.0           1409.7           Asia    False\n",
       "France                  2925096.0             67.2         Europe     True\n",
       "Netherlands              945327.0             17.2         Europe     True\n",
       "United States          20412870.0            327.4  North America     True\n",
       "Uruguay                   63370.0              3.5  South America    False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"visited\"] = [False, False, True, True, True, False]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** add another column called 'GDP per capita (nominal, \\$)' to `df2`. The values are the nominal GDP per capita, which can be calculated with the data in the other columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>False</td>\n",
       "      <td>60010.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>12740.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>54960.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "      <td>True</td>\n",
       "      <td>62348.411729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>South America</td>\n",
       "      <td>False</td>\n",
       "      <td>18105.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents  visited  \\\n",
       "Australia               1500256.0             25.0        Oceania    False   \n",
       "China                  17960000.0           1409.7           Asia    False   \n",
       "France                  2925096.0             67.2         Europe     True   \n",
       "Netherlands              945327.0             17.2         Europe     True   \n",
       "United States          20412870.0            327.4  North America     True   \n",
       "Uruguay                   63370.0              3.5  South America    False   \n",
       "\n",
       "               GDP per capita (nominal, $)  \n",
       "Australia                     60010.240000  \n",
       "China                         12740.299354  \n",
       "France                        43528.214286  \n",
       "Netherlands                   54960.872093  \n",
       "United States                 62348.411729  \n",
       "Uruguay                       18105.714286  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"GDP per capita (nominal, $)\"] = df2[\"GDP (nominal, $MM)\"] / df2[\"population (MM)\"]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14:** sort the rows of `df2` by GDP per capita in descending order and show the resulting `df2` as output. (Hint: choose between `sort_index` and `sort_values` which one to use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "      <td>True</td>\n",
       "      <td>62348.411729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>False</td>\n",
       "      <td>60010.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>54960.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>63370.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>South America</td>\n",
       "      <td>False</td>\n",
       "      <td>18105.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>12740.299354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents  visited  \\\n",
       "United States          20412870.0            327.4  North America     True   \n",
       "Australia               1500256.0             25.0        Oceania    False   \n",
       "Netherlands              945327.0             17.2         Europe     True   \n",
       "France                  2925096.0             67.2         Europe     True   \n",
       "Uruguay                   63370.0              3.5  South America    False   \n",
       "China                  17960000.0           1409.7           Asia    False   \n",
       "\n",
       "               GDP per capita (nominal, $)  \n",
       "United States                 62348.411729  \n",
       "Australia                     60010.240000  \n",
       "Netherlands                   54960.872093  \n",
       "France                        43528.214286  \n",
       "Uruguay                       18105.714286  \n",
       "China                         12740.299354  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(by=\"GDP per capita (nominal, $)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and filtering\n",
    "\n",
    "There exist two methods  for slicing a DataFrame: `loc` when using index/column names and `iloc` when using integers to specify rows/columns. Note that slicing with `loc` is inclusive with respect to the last element, while slicing with `iloc` is exclusive (as was the case for NumPy's ndarrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15:** use `loc` to extract the row about the Netherlands from `df2`. (Note that in this case a Series is returned.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GDP (nominal, $MM)                 945327.0\n",
       "population (MM)                        17.2\n",
       "Continents                           Europe\n",
       "visited                                True\n",
       "GDP per capita (nominal, $)    54960.872093\n",
       "Name: Netherlands, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[\"Netherlands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 16:** use `loc` to extract the rows up to and including the Netherlands from `df2`. (Note that in this case a DataFrame is returned.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>False</td>\n",
       "      <td>60010.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>12740.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>54960.872093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GDP (nominal, $MM)  population (MM) Continents  visited  \\\n",
       "Australia             1500256.0             25.0    Oceania    False   \n",
       "China                17960000.0           1409.7       Asia    False   \n",
       "France                2925096.0             67.2     Europe     True   \n",
       "Netherlands            945327.0             17.2     Europe     True   \n",
       "\n",
       "             GDP per capita (nominal, $)  \n",
       "Australia                   60010.240000  \n",
       "China                       12740.299354  \n",
       "France                      43528.214286  \n",
       "Netherlands                 54960.872093  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[:\"Netherlands\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 17:** extract the rows up to and including the Netherlands from `df2`, and only the columns about the population and GDP per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Australia      60010.240000\n",
       "China          12740.299354\n",
       "France         43528.214286\n",
       "Netherlands    54960.872093\n",
       "Name: GDP per capita (nominal, $), dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[:\"Netherlands\"][\"GDP per capita (nominal, $)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 18:** if you have used `loc` in the previous exercise, now use `iloc` to repeat it (and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1500256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>False</td>\n",
       "      <td>60010.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>12740.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>54960.872093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GDP (nominal, $MM)  population (MM) Continents  visited  \\\n",
       "Australia             1500256.0             25.0    Oceania    False   \n",
       "China                17960000.0           1409.7       Asia    False   \n",
       "France                2925096.0             67.2     Europe     True   \n",
       "Netherlands            945327.0             17.2     Europe     True   \n",
       "\n",
       "             GDP per capita (nominal, $)  \n",
       "Australia                   60010.240000  \n",
       "China                       12740.299354  \n",
       "France                      43528.214286  \n",
       "Netherlands                 54960.872093  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Australia      60010.240000\n",
       "China          12740.299354\n",
       "France         43528.214286\n",
       "Netherlands    54960.872093\n",
       "Name: GDP per capita (nominal, $), dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[:4][\"GDP per capita (nominal, $)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 19:** filtering rows from a DataFrame proceeds in the same fashion as for NumPy's ndarray, i.e. by using broadcasting with a Series of booleans. Create a DataFrame including only those countries in `df2` whose population is above 50 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>17960000.0</td>\n",
       "      <td>1409.7</td>\n",
       "      <td>Asia</td>\n",
       "      <td>False</td>\n",
       "      <td>12740.299354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "      <td>True</td>\n",
       "      <td>62348.411729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents  visited  \\\n",
       "China                  17960000.0           1409.7           Asia    False   \n",
       "France                  2925096.0             67.2         Europe     True   \n",
       "United States          20412870.0            327.4  North America     True   \n",
       "\n",
       "               GDP per capita (nominal, $)  \n",
       "China                         12740.299354  \n",
       "France                        43528.214286  \n",
       "United States                 62348.411729  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"population (MM)\"] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 20:** create a DataFrame with only the countries you have visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP (nominal, $MM)</th>\n",
       "      <th>population (MM)</th>\n",
       "      <th>Continents</th>\n",
       "      <th>visited</th>\n",
       "      <th>GDP per capita (nominal, $)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2925096.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>43528.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>945327.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>54960.872093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>20412870.0</td>\n",
       "      <td>327.4</td>\n",
       "      <td>North America</td>\n",
       "      <td>True</td>\n",
       "      <td>62348.411729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GDP (nominal, $MM)  population (MM)     Continents  visited  \\\n",
       "France                  2925096.0             67.2         Europe     True   \n",
       "Netherlands              945327.0             17.2         Europe     True   \n",
       "United States          20412870.0            327.4  North America     True   \n",
       "\n",
       "               GDP per capita (nominal, $)  \n",
       "France                        43528.214286  \n",
       "Netherlands                   54960.872093  \n",
       "United States                 62348.411729  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"visited\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DataFrame manipulation\n",
    "\n",
    "In the following exercises we will be working with existing data. The data is stored in an Excel file ('weather_accident_data.xlsx') and can be found on Canvas. The goal is to become acquainted with basic data cleaning and manipulation of data in a pandas DataFrame.\n",
    "\n",
    "The data consists of daily weather data for the Netherlands for January 2018 and the daily number of traffic accidents during the same period. Parts of the data are fictional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 21:** import the Excel file ('weather_accident_data.xlsx') as a pandas DataFrame. The simplest way to do this is to put the Excel file in the same folder as the Jupyter notebook and the use the `read_excel` function. Inspect the data by printing it. It includes information about: \n",
    "* the date\n",
    "* wind\n",
    "* average temperature\n",
    "* minimum temperature\n",
    "* maximum temperature\n",
    "* hours of sun\n",
    "* hours of rain\n",
    "* amount of rain\n",
    "* fog\n",
    "* snow\n",
    "* issuing of a weather alarm\n",
    "* the number of traffic accidents\n",
    "\n",
    "The structure of the Excel file is not very practical. We would like each row to become a column in the pandas DataFrame, so you will need to transpose the data. The first column in the Excel file should become the column names of the DataFrame. The index of the DataFrame should be the default (i.e. integers starting at 0). \n",
    "\n",
    "Finally, give the created DataFrame the name `df` and print the first ten rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>-</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow</th>\n",
       "      <th>test_probe</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180123</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>###</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180201</td>\n",
       "      <td>2.8bft</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180131</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180114</td>\n",
       "      <td>2.9bft</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8bft</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20180120</td>\n",
       "      <td>2.1bft</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20171230</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20180103</td>\n",
       "      <td>4.8bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20180129</td>\n",
       "      <td>3.6bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   YYYYMMDD       - T_ave T_low T_high  sun rain_duration rain(mm)  fog snow  \\\n",
       "1   20180123  3.2bft   8.1   4.6   11.2  0.9             4      1.5  m/e    4   \n",
       "2   20180201  2.8bft   3.4   1.9    6.1  2.5           4.3      4.4    m    0   \n",
       "3   20180131  3.4bft   6.5   3.2    9.5    0           6.4      3.8    m    0   \n",
       "4   20180114  2.9bft   2.9   0.8    5.2    5             0        0    -    0   \n",
       "5   20180105  2.8bft   6.4   4.4    8.7    0           2.4      2.7    m    0   \n",
       "6   20180120  2.1bft   2.2   0.8    3.6  0.4           NaN      NaN  m/e    1   \n",
       "7   20171230  3.5bft   8.8   3.9   12.2    0             5      3.7    -    0   \n",
       "8   20180103  4.8bft   8.8   5.4   11.2  0.2           5.1      9.5    -    0   \n",
       "9   20180102  3.0bft   6.5   4.5    9.1  1.4           6.2      4.5    -    0   \n",
       "10  20180129  3.6bft   8.8   4.6   10.7    0           2.8      5.2    -    0   \n",
       "\n",
       "0  test_probe weather alarm accidents  \n",
       "1         ###    red: storm        83  \n",
       "2         ###           NaN        91  \n",
       "3         ###           NaN        86  \n",
       "4         ###           NaN        92  \n",
       "5         ###           NaN        75  \n",
       "6         ###           NaN        74  \n",
       "7         ###           NaN       114  \n",
       "8         ###           NaN       135  \n",
       "9         ###           NaN       102  \n",
       "10        ###           NaN       124  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"weather_accident_data.xlsx\",header=None).T\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 22:** the name of the wind column is '-' instead of 'wind'. Give the column the correct name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"-\": \"wind\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 23:** sort the rows of the DataFrame by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow</th>\n",
       "      <th>test_probe</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20171229</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20171230</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20171231</td>\n",
       "      <td>3.8bft</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20180101</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   YYYYMMDD    wind T_ave T_low T_high  sun rain_duration rain(mm) fog snow  \\\n",
       "27  20171229  3.2bft   2.8  -0.7    6.7  0.3           6.3      6.7   -    0   \n",
       "7   20171230  3.5bft   8.8   3.9   12.2    0             5      3.7   -    0   \n",
       "21  20171231  3.8bft  10.6   8.5   13.7  0.2          15.3     39.3   -    0   \n",
       "11  20180101  3.2bft   6.8   5.2    8.8  2.1           6.9      4.7   -    0   \n",
       "9   20180102  3.0bft   6.5   4.5    9.1  1.4           6.2      4.5   -    0   \n",
       "\n",
       "0  test_probe weather alarm accidents  \n",
       "27        ###           NaN       125  \n",
       "7         ###           NaN       114  \n",
       "21        ###           NaN       416  \n",
       "11        ###           NaN        91  \n",
       "9         ###           NaN       102  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"YYYYMMDD\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 24:** note that the index of `df` is mixed up due to the sorting. Reset the index of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 25:** accidentally the data set includes a few days in December and February. Remove those rows from `df` and reset the index again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow</th>\n",
       "      <th>test_probe</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20180101</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>20180103</td>\n",
       "      <td>4.8bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>20180104</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8bft</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>20180106</td>\n",
       "      <td>2.2bft</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>20180107</td>\n",
       "      <td>3.6bft</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>20180108</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>20180109</td>\n",
       "      <td>2.4bft</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>20180110</td>\n",
       "      <td>2.2bft</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>20180111</td>\n",
       "      <td>1.5bft</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>20180112</td>\n",
       "      <td>1.4bft</td>\n",
       "      <td>5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>20180113</td>\n",
       "      <td>2.3bft</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>20180114</td>\n",
       "      <td>2.9bft</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>20180115</td>\n",
       "      <td>3.9bft</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>20180116</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>20180117</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>20180118</td>\n",
       "      <td>3.8bft</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>20180119</td>\n",
       "      <td>2.3bft</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>20180120</td>\n",
       "      <td>2.1bft</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>20180121</td>\n",
       "      <td>2.1bft</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>###</td>\n",
       "      <td>yellow: storm</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>20180122</td>\n",
       "      <td>2.5bft</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>###</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>20180123</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>###</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>20180124</td>\n",
       "      <td>4.1bft</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>20180125</td>\n",
       "      <td>2.7bft</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34</td>\n",
       "      <td>20180126</td>\n",
       "      <td>1.6bft</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>20180127</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>20180128</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>20180129</td>\n",
       "      <td>3.6bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>20180130</td>\n",
       "      <td>2.0bft</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>20180131</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   index  YYYYMMDD    wind T_ave T_low T_high  sun rain_duration rain(mm)  \\\n",
       "0      11  20180101  3.2bft   6.8   5.2    8.8  2.1           6.9      4.7   \n",
       "1       9  20180102  3.0bft   6.5   4.5    9.1  1.4           6.2      4.5   \n",
       "2       8  20180103  4.8bft   8.8   5.4   11.2  0.2           5.1      9.5   \n",
       "3      29  20180104  3.5bft   8.2   6.8   10.7  0.2           1.6      0.6   \n",
       "4       5  20180105  2.8bft   6.4   4.4    8.7    0           2.4      2.7   \n",
       "5      19  20180106  2.2bft   4.5   2.2    6.6  0.7             0        0   \n",
       "6      33  20180107  3.6bft     1  -1.2    3.1  6.2             0        0   \n",
       "7      30  20180108  3.5bft   1.1  -1.4    3.9  6.5             0        0   \n",
       "8      35  20180109  2.4bft     3  -0.2    6.1  0.3             0        0   \n",
       "9      22  20180110  2.2bft   6.9   5.8    7.6    0           5.8      2.6   \n",
       "10     24  20180111  1.5bft   5.7   2.8    7.6    0             0        0   \n",
       "11     20  20180112  1.4bft     5   4.1    5.9    0             0        0   \n",
       "12     26  20180113  2.3bft   4.2   1.2    6.2    0             0        0   \n",
       "13      4  20180114  2.9bft   2.9   0.8    5.2    5             0        0   \n",
       "14     32  20180115  3.9bft   5.2   1.7      8    0           9.5     13.3   \n",
       "15     13  20180116  3.2bft   5.2   2.5    6.9  2.9           3.9      8.3   \n",
       "16     28  20180117  3.4bft   4.6     2      6  0.5           2.2      2.7   \n",
       "17     16  20180118  3.8bft   4.7   0.5   10.2  0.4           NaN      NaN   \n",
       "18     25  20180119  2.3bft   3.7   1.4    6.9  2.5           3.1      5.4   \n",
       "19      6  20180120  2.1bft   2.2   0.8    3.6  0.4           NaN      NaN   \n",
       "20     31  20180121  2.1bft     3  -0.4    6.9  4.8           2.7      2.1   \n",
       "21     17  20180122  2.5bft   6.3     2    8.4  0.5           1.9      0.6   \n",
       "22      1  20180123  3.2bft   8.1   4.6   11.2  0.9             4      1.5   \n",
       "23     12  20180124  4.1bft  11.7   7.3   14.4    0           4.1      4.2   \n",
       "24     18  20180125  2.7bft   7.7     5    9.2  0.6           0.1      0.1   \n",
       "25     34  20180126  1.6bft   5.4   2.5    8.6  1.2             0        0   \n",
       "26     14  20180127  3.2bft   5.8   4.4    7.2    2           3.6      1.1   \n",
       "27     23  20180128  3.4bft   9.7   6.9   10.8  1.7             0     -0.1   \n",
       "28     10  20180129  3.6bft   8.8   4.6   10.7    0           2.8      5.2   \n",
       "29     15  20180130  2.0bft   4.7   2.1    7.4  6.2             0        0   \n",
       "30      3  20180131  3.4bft   6.5   3.2    9.5    0           6.4      3.8   \n",
       "\n",
       "0   fog snow test_probe  weather alarm accidents  \n",
       "0     -    0        ###            NaN        91  \n",
       "1     -    0        ###            NaN       102  \n",
       "2     -    0        ###            NaN       135  \n",
       "3     m    0        ###            NaN        68  \n",
       "4     m    0        ###            NaN        75  \n",
       "5     m    0        ###            NaN        53  \n",
       "6   m/e    0        ###  yellow: icing        69  \n",
       "7   m/e    0        ###  yellow: icing        68  \n",
       "8   m/e    0        ###  yellow: icing        63  \n",
       "9     m    0        ###            NaN        61  \n",
       "10    m    0        ###            NaN        83  \n",
       "11    -    0        ###            NaN        60  \n",
       "12    -    0        ###            NaN        50  \n",
       "13    -    0        ###            NaN        92  \n",
       "14    -    0        ###            NaN       217  \n",
       "15    -    0        ###            NaN       151  \n",
       "16    -    0        ###            NaN        95  \n",
       "17    -    0        ###            NaN       186  \n",
       "18    -    1        ###            NaN       143  \n",
       "19  m/e    1        ###            NaN        74  \n",
       "20  m/e    1        ###  yellow: storm       113  \n",
       "21  m/e    4        ###     red: storm        64  \n",
       "22  m/e    4        ###     red: storm        83  \n",
       "23    e    1        ###            NaN       101  \n",
       "24    e    0        ###            NaN        74  \n",
       "25  m/e    0        ###            NaN        47  \n",
       "26  m/e    0        ###            NaN        68  \n",
       "27    -    0        ###            NaN        38  \n",
       "28    -    0        ###            NaN       124  \n",
       "29    m    0        ###            NaN        77  \n",
       "30    m    0        ###            NaN        86  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"YYYYMMDD\"] = df[\"YYYYMMDD\"].apply(str)\n",
    "df = df[~df[\"YYYYMMDD\"].str.contains(\"....[0,1]2..\")]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 26:** the column 'test_probe' was created in the data collection process, but does not contain any information. Remove that column from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['test_probe'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_probe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['test_probe'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(columns=[\"test_probe\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** NumPy's universal functions can also be applied to Series and DataFrames. Note that we use `astype` to create a Series/DataFrame with data of the same type. NumPy's universal functions require this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      109.947172\n",
      "1       90.017131\n",
      "2    13359.726830\n",
      "3        1.822119\n",
      "4       14.879732\n",
      "Name: rain(mm), dtype: float64\n",
      "\n",
      "\n",
      "0      rain(mm)  rain_duration\n",
      "0    109.947172     992.274716\n",
      "1     90.017131     492.749041\n",
      "2  13359.726830     164.021907\n",
      "3      1.822119       4.953032\n",
      "4     14.879732      11.023176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3.6\n",
       "1    4.6\n",
       "2    5.8\n",
       "3    3.9\n",
       "4    4.3\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.exp(df['rain(mm)'].astype(float)).head(5)) # Applying a universal function to a Series.\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(np.exp(df[['rain(mm)', 'rain_duration']].astype(float)).head(5)) # Applying a universal function to a DataFrame.\n",
    "\n",
    "np.subtract(df['T_high'], df['T_low']).head(5) # Applying a binary universal function to two Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** pandas objects have a number of mathematical and statistical methods. Most of them are reductions (i.e., they extract a single value from a Series or (columns/rows of) a DataFrame) and are similar to the NumPy methods. An important difference is that the pandas methods can handle missing values by ignoring them. For example, in the cell below we compute the standard deviation on a NumPy array and a Series, both containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "2.6669847921901244\n"
     ]
    }
   ],
   "source": [
    "print(df['rain_duration'].values.std()) # Applying a reduction to an ndarray. The values attribute returns a NumPy array.\n",
    "\n",
    "print(df['rain_duration'].std()) # Applying a reduction to a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 27:** the data in the 'rain(mm)' column needs some cleaning:\n",
    "* one of the entries accidentally has a minus sign. Remove the minus sign.\n",
    "* replace the missing values by the daily average amount of rain for January. (Hint: use `fillna`.)\n",
    "* round the values to 1 decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20180101</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>20180103</td>\n",
       "      <td>4.8bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>20180104</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8bft</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>20180106</td>\n",
       "      <td>2.2bft</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>20180107</td>\n",
       "      <td>3.6bft</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>20180108</td>\n",
       "      <td>3.5bft</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>20180109</td>\n",
       "      <td>2.4bft</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>20180110</td>\n",
       "      <td>2.2bft</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>20180111</td>\n",
       "      <td>1.5bft</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>20180112</td>\n",
       "      <td>1.4bft</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>20180113</td>\n",
       "      <td>2.3bft</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>20180114</td>\n",
       "      <td>2.9bft</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>20180115</td>\n",
       "      <td>3.9bft</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>20180116</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>8.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>20180117</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>20180118</td>\n",
       "      <td>3.8bft</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>20180119</td>\n",
       "      <td>2.3bft</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>20180120</td>\n",
       "      <td>2.1bft</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>2.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>20180121</td>\n",
       "      <td>2.1bft</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow: storm</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>20180122</td>\n",
       "      <td>2.5bft</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>20180123</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>20180124</td>\n",
       "      <td>4.1bft</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>20180125</td>\n",
       "      <td>2.7bft</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34</td>\n",
       "      <td>20180126</td>\n",
       "      <td>1.6bft</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>20180127</td>\n",
       "      <td>3.2bft</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>20180128</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>20180129</td>\n",
       "      <td>3.6bft</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>20180130</td>\n",
       "      <td>2.0bft</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>20180131</td>\n",
       "      <td>3.4bft</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   index  YYYYMMDD    wind  T_ave  T_low  T_high  sun  rain_duration  \\\n",
       "0      11  20180101  3.2bft    6.8    5.2     8.8  2.1       6.900000   \n",
       "1       9  20180102  3.0bft    6.5    4.5     9.1  1.4       6.200000   \n",
       "2       8  20180103  4.8bft    8.8    5.4    11.2  0.2       5.100000   \n",
       "3      29  20180104  3.5bft    8.2    6.8    10.7  0.2       1.600000   \n",
       "4       5  20180105  2.8bft    6.4    4.4     8.7  0.0       2.400000   \n",
       "5      19  20180106  2.2bft    4.5    2.2     6.6  0.7       0.000000   \n",
       "6      33  20180107  3.6bft    1.0   -1.2     3.1  6.2       0.000000   \n",
       "7      30  20180108  3.5bft    1.1   -1.4     3.9  6.5       0.000000   \n",
       "8      35  20180109  2.4bft    3.0   -0.2     6.1  0.3       0.000000   \n",
       "9      22  20180110  2.2bft    6.9    5.8     7.6  0.0       5.800000   \n",
       "10     24  20180111  1.5bft    5.7    2.8     7.6  0.0       0.000000   \n",
       "11     20  20180112  1.4bft    5.0    4.1     5.9  0.0       0.000000   \n",
       "12     26  20180113  2.3bft    4.2    1.2     6.2  0.0       0.000000   \n",
       "13      4  20180114  2.9bft    2.9    0.8     5.2  5.0       0.000000   \n",
       "14     32  20180115  3.9bft    5.2    1.7     8.0  0.0       9.500000   \n",
       "15     13  20180116  3.2bft    5.2    2.5     6.9  2.9       3.900000   \n",
       "16     28  20180117  3.4bft    4.6    2.0     6.0  0.5       2.200000   \n",
       "17     16  20180118  3.8bft    4.7    0.5    10.2  0.4       2.517241   \n",
       "18     25  20180119  2.3bft    3.7    1.4     6.9  2.5       3.100000   \n",
       "19      6  20180120  2.1bft    2.2    0.8     3.6  0.4       2.517241   \n",
       "20     31  20180121  2.1bft    3.0   -0.4     6.9  4.8       2.700000   \n",
       "21     17  20180122  2.5bft    6.3    2.0     8.4  0.5       1.900000   \n",
       "22      1  20180123  3.2bft    8.1    4.6    11.2  0.9       4.000000   \n",
       "23     12  20180124  4.1bft   11.7    7.3    14.4  0.0       4.100000   \n",
       "24     18  20180125  2.7bft    7.7    5.0     9.2  0.6       0.100000   \n",
       "25     34  20180126  1.6bft    5.4    2.5     8.6  1.2       0.000000   \n",
       "26     14  20180127  3.2bft    5.8    4.4     7.2  2.0       3.600000   \n",
       "27     23  20180128  3.4bft    9.7    6.9    10.8  1.7       0.000000   \n",
       "28     10  20180129  3.6bft    8.8    4.6    10.7  0.0       2.800000   \n",
       "29     15  20180130  2.0bft    4.7    2.1     7.4  6.2       0.000000   \n",
       "30      3  20180131  3.4bft    6.5    3.2     9.5  0.0       6.400000   \n",
       "\n",
       "0   rain(mm)  fog  snow  weather alarm  accidents  \n",
       "0        4.7    -     0       2.517241         91  \n",
       "1        4.5    -     0       2.517241        102  \n",
       "2        9.5    -     0       2.517241        135  \n",
       "3        0.6    m     0       2.517241         68  \n",
       "4        2.7    m     0       2.517241         75  \n",
       "5        0.0    m     0       2.517241         53  \n",
       "6        0.0  m/e     0  yellow: icing         69  \n",
       "7        0.0  m/e     0  yellow: icing         68  \n",
       "8        0.0  m/e     0  yellow: icing         63  \n",
       "9        2.6    m     0       2.517241         61  \n",
       "10       0.0    m     0       2.517241         83  \n",
       "11       0.0    -     0       2.517241         60  \n",
       "12       0.0    -     0       2.517241         50  \n",
       "13       0.0    -     0       2.517241         92  \n",
       "14      13.3    -     0       2.517241        217  \n",
       "15       8.3    -     0       2.517241        151  \n",
       "16       2.7    -     0       2.517241         95  \n",
       "17       2.5    -     0       2.517241        186  \n",
       "18       5.4    -     1       2.517241        143  \n",
       "19       2.5  m/e     1       2.517241         74  \n",
       "20       2.1  m/e     1  yellow: storm        113  \n",
       "21       0.6  m/e     4     red: storm         64  \n",
       "22       1.5  m/e     4     red: storm         83  \n",
       "23       4.2    e     1       2.517241        101  \n",
       "24       0.1    e     0       2.517241         74  \n",
       "25       0.0  m/e     0       2.517241         47  \n",
       "26       1.1  m/e     0       2.517241         68  \n",
       "27       0.1    -     0       2.517241         38  \n",
       "28       5.2    -     0       2.517241        124  \n",
       "29       0.0    m     0       2.517241         77  \n",
       "30       3.8    m     0       2.517241         86  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rain(mm)\"] = df[\"rain(mm)\"].abs()\n",
    "df[\"rain(mm)\"] = df[\"rain(mm)\"].astype(float)\n",
    "df.fillna(df[\"rain(mm)\"].mean(), inplace=True)\n",
    "df[\"rain(mm)\"] = df[\"rain(mm)\"].round(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 28:** the values of the 'wind' column are strings. Replace them by numerical types, leaving out the 'bft'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>fog</th>\n",
       "      <th>snow</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20180101</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>20180103</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>20180104</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>20180106</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>20180107</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>20180108</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>20180109</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>yellow: icing</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>20180110</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>20180111</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>20180112</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>20180113</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>20180114</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>20180115</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>20180116</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>8.3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>20180117</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>20180118</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>20180119</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>20180120</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>2.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>20180121</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>1</td>\n",
       "      <td>yellow: storm</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>20180122</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>20180123</td>\n",
       "      <td>3.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>m/e</td>\n",
       "      <td>4</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>20180124</td>\n",
       "      <td>4.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>20180125</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>34</td>\n",
       "      <td>20180126</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>20180127</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>m/e</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>20180128</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>20180129</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>20180130</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>20180131</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   index  YYYYMMDD  wind  T_ave  T_low  T_high  sun  rain_duration  rain(mm)  \\\n",
       "0      11  20180101   3.2    6.8    5.2     8.8  2.1       6.900000       4.7   \n",
       "1       9  20180102   3.0    6.5    4.5     9.1  1.4       6.200000       4.5   \n",
       "2       8  20180103   4.8    8.8    5.4    11.2  0.2       5.100000       9.5   \n",
       "3      29  20180104   3.5    8.2    6.8    10.7  0.2       1.600000       0.6   \n",
       "4       5  20180105   2.8    6.4    4.4     8.7  0.0       2.400000       2.7   \n",
       "5      19  20180106   2.2    4.5    2.2     6.6  0.7       0.000000       0.0   \n",
       "6      33  20180107   3.6    1.0   -1.2     3.1  6.2       0.000000       0.0   \n",
       "7      30  20180108   3.5    1.1   -1.4     3.9  6.5       0.000000       0.0   \n",
       "8      35  20180109   2.4    3.0   -0.2     6.1  0.3       0.000000       0.0   \n",
       "9      22  20180110   2.2    6.9    5.8     7.6  0.0       5.800000       2.6   \n",
       "10     24  20180111   1.5    5.7    2.8     7.6  0.0       0.000000       0.0   \n",
       "11     20  20180112   1.4    5.0    4.1     5.9  0.0       0.000000       0.0   \n",
       "12     26  20180113   2.3    4.2    1.2     6.2  0.0       0.000000       0.0   \n",
       "13      4  20180114   2.9    2.9    0.8     5.2  5.0       0.000000       0.0   \n",
       "14     32  20180115   3.9    5.2    1.7     8.0  0.0       9.500000      13.3   \n",
       "15     13  20180116   3.2    5.2    2.5     6.9  2.9       3.900000       8.3   \n",
       "16     28  20180117   3.4    4.6    2.0     6.0  0.5       2.200000       2.7   \n",
       "17     16  20180118   3.8    4.7    0.5    10.2  0.4       2.517241       2.5   \n",
       "18     25  20180119   2.3    3.7    1.4     6.9  2.5       3.100000       5.4   \n",
       "19      6  20180120   2.1    2.2    0.8     3.6  0.4       2.517241       2.5   \n",
       "20     31  20180121   2.1    3.0   -0.4     6.9  4.8       2.700000       2.1   \n",
       "21     17  20180122   2.5    6.3    2.0     8.4  0.5       1.900000       0.6   \n",
       "22      1  20180123   3.2    8.1    4.6    11.2  0.9       4.000000       1.5   \n",
       "23     12  20180124   4.1   11.7    7.3    14.4  0.0       4.100000       4.2   \n",
       "24     18  20180125   2.7    7.7    5.0     9.2  0.6       0.100000       0.1   \n",
       "25     34  20180126   1.6    5.4    2.5     8.6  1.2       0.000000       0.0   \n",
       "26     14  20180127   3.2    5.8    4.4     7.2  2.0       3.600000       1.1   \n",
       "27     23  20180128   3.4    9.7    6.9    10.8  1.7       0.000000       0.1   \n",
       "28     10  20180129   3.6    8.8    4.6    10.7  0.0       2.800000       5.2   \n",
       "29     15  20180130   2.0    4.7    2.1     7.4  6.2       0.000000       0.0   \n",
       "30      3  20180131   3.4    6.5    3.2     9.5  0.0       6.400000       3.8   \n",
       "\n",
       "0   fog  snow  weather alarm  accidents  \n",
       "0     -     0       2.517241         91  \n",
       "1     -     0       2.517241        102  \n",
       "2     -     0       2.517241        135  \n",
       "3     m     0       2.517241         68  \n",
       "4     m     0       2.517241         75  \n",
       "5     m     0       2.517241         53  \n",
       "6   m/e     0  yellow: icing         69  \n",
       "7   m/e     0  yellow: icing         68  \n",
       "8   m/e     0  yellow: icing         63  \n",
       "9     m     0       2.517241         61  \n",
       "10    m     0       2.517241         83  \n",
       "11    -     0       2.517241         60  \n",
       "12    -     0       2.517241         50  \n",
       "13    -     0       2.517241         92  \n",
       "14    -     0       2.517241        217  \n",
       "15    -     0       2.517241        151  \n",
       "16    -     0       2.517241         95  \n",
       "17    -     0       2.517241        186  \n",
       "18    -     1       2.517241        143  \n",
       "19  m/e     1       2.517241         74  \n",
       "20  m/e     1  yellow: storm        113  \n",
       "21  m/e     4     red: storm         64  \n",
       "22  m/e     4     red: storm         83  \n",
       "23    e     1       2.517241        101  \n",
       "24    e     0       2.517241         74  \n",
       "25  m/e     0       2.517241         47  \n",
       "26  m/e     0       2.517241         68  \n",
       "27    -     0       2.517241         38  \n",
       "28    -     0       2.517241        124  \n",
       "29    m     0       2.517241         77  \n",
       "30    m     0       2.517241         86  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"wind\"] = df[\"wind\"].str.replace(\"bft\", \"\").astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 29:** the 'fog' column indicates whether there was fog in the morning ('m'), evening ('e') or both morning and evening ('m/e'). Add a column to `df` called 'fog_morning' of boolean values, indicating whether there was fog in the morning. Likewise, create a column 'fog_evening'. Finally, remove the original 'fog' column from `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fog_morning\"] = df[\"fog\"].str.replace(\"m\", \"1\").replace(\"\", \"0\").replace(\"e\", \"0\").replace(\"m/e\", \"1\").astype(bool)\n",
    "df[\"fog_evening\"] = df[\"fog\"].str.replace(\"e\", \"1\").replace(\"\", \"0\").replace(\"m\", \"0\").replace(\"m/e\", \"1\").astype(bool)\n",
    "df.drop(columns=[\"fog\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 30:** sometimes it is useful to bin quantitative data into categories. Add a column to `df` called 'rain_intensity', whose values are strings representing rain categories depending on the amount of rain:\n",
    "* 'no rain': 0 mm\n",
    "* 'light rain': (0, 5] mm\n",
    "* 'medium rain': (5, 10] mm\n",
    "* 'heavy rain': (10, 50] mm\n",
    "\n",
    "(Hint: pp. 203-205 of McKinney.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rain_intensity\"] = pd.cut(df[\"rain(mm)\"], bins=[-1, 0, 5, 10, 50], labels=[\"no rain\", \"light rain\", \"medium rain\", \"heavy rain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 31:** create a Series that counts the frequency of the occurrence of the different rain categories in January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rain_intensity\n",
       "light rain     16\n",
       "no rain        10\n",
       "medium rain     4\n",
       "heavy rain      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rain_intensity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** the `sample` method draws a random sample of rows (or columns) from a Series or DataFrame. Drawing a sample of the size of the DataFrame is an easy way to randomly reorder the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>snow</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "      <th>fog_morning</th>\n",
       "      <th>fog_evening</th>\n",
       "      <th>rain_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>20180128</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>20180104</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>20180116</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>151</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>medium rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>20180122</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>red: storm</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   index  YYYYMMDD  wind  T_ave  T_low  T_high  sun  rain_duration  rain(mm)  \\\n",
       "4       5  20180105   2.8    6.4    4.4     8.7  0.0            2.4       2.7   \n",
       "27     23  20180128   3.4    9.7    6.9    10.8  1.7            0.0       0.1   \n",
       "3      29  20180104   3.5    8.2    6.8    10.7  0.2            1.6       0.6   \n",
       "15     13  20180116   3.2    5.2    2.5     6.9  2.9            3.9       8.3   \n",
       "21     17  20180122   2.5    6.3    2.0     8.4  0.5            1.9       0.6   \n",
       "\n",
       "0   snow weather alarm  accidents  fog_morning  fog_evening rain_intensity  \n",
       "4      0      2.517241         75         True         True     light rain  \n",
       "27     0      2.517241         38         True         True     light rain  \n",
       "3      0      2.517241         68         True         True     light rain  \n",
       "15     0      2.517241        151         True         True    medium rain  \n",
       "21     4    red: storm         64         True         True     light rain  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "There are numerous modules that have built-in functions to compute correlations and covariances. They all have advantages and disadvantages and depending on the situation you can choose to use a specific module. We here give two examples: `corr` from the pandas module and `pearsonr` from SciPy's stats module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** here we use pandas' `corr` function to compute the correlation between the 'wind' and 'accidents' columns. There are two disadvantages of the `corr` function: you need to make sure that the entries are all of the same type (e.g. by using `astype`) and it does not calculate the p-value of the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.46885840130424355)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['wind'].astype(float)).corr(df['accidents'].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** the `pearsonr` function of the stats module of the SciPy package calculates both the correlation and the p-value (it returns a tuple of the two quantities). The main disadvantage of `pearsonr` is that it cannot handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=np.float64(0.46885840130424355), pvalue=np.float64(0.007801325106885124))\n",
      "PearsonRResult(statistic=np.float64(0.5922943256638151), pvalue=np.float64(0.0004475042650265651))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats # Importing the stats module of the SciPy package.\n",
    "\n",
    "print(stats.pearsonr(df['wind'],df['accidents'])) # Pearsonr returns a tuple of the correlation and the p-value.\n",
    "\n",
    "try:\n",
    "    print(stats.pearsonr(df['rain_duration'],df['accidents']))\n",
    "except:\n",
    "    print(\"Pearsonr cannot handle missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 32:** define a function called `my_correlation` whose input arguments are two equal-length Series and whose output is a tuple of the correlation and the p-value. In contrast to the `pearsonr` function, `my_correlation` should be able to handle missing values by eliminating entry lines containing missing values from both(!) Series. Test `my_correlation` by computing the correlation and p-value of 'rain_duration' and 'accidents'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=np.float64(0.5922943256638151), pvalue=np.float64(0.0004475042650265651))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_correlation(x: pd.Series, y: pd.Series) -> tuple[float, float]:\n",
    "    x = x.dropna()\n",
    "    y = y.dropna()\n",
    "    return stats.pearsonr(x, y)\n",
    "my_correlation(df['rain_duration'],df['accidents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 33:** create a dictionary whose keys are the column names and whose values are the correlation of the specific column with the 'accidents' column. Include only those columns for which a meaningful correlation can be computed. (Hint: define a list of names of the relevant columns and use a dictionary comprehension.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>YYYYMMDD</th>\n",
       "      <th>wind</th>\n",
       "      <th>T_ave</th>\n",
       "      <th>T_low</th>\n",
       "      <th>T_high</th>\n",
       "      <th>sun</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain(mm)</th>\n",
       "      <th>snow</th>\n",
       "      <th>weather alarm</th>\n",
       "      <th>accidents</th>\n",
       "      <th>fog_morning</th>\n",
       "      <th>fog_evening</th>\n",
       "      <th>rain_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20180101</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>91</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>20180102</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>102</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>20180103</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>135</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>medium rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>20180104</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20180105</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>light rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  index  YYYYMMDD  wind  T_ave  T_low  T_high  sun  rain_duration  rain(mm)  \\\n",
       "0     11  20180101   3.2    6.8    5.2     8.8  2.1            6.9       4.7   \n",
       "1      9  20180102   3.0    6.5    4.5     9.1  1.4            6.2       4.5   \n",
       "2      8  20180103   4.8    8.8    5.4    11.2  0.2            5.1       9.5   \n",
       "3     29  20180104   3.5    8.2    6.8    10.7  0.2            1.6       0.6   \n",
       "4      5  20180105   2.8    6.4    4.4     8.7  0.0            2.4       2.7   \n",
       "\n",
       "0  snow weather alarm  accidents  fog_morning  fog_evening rain_intensity  \n",
       "0     0      2.517241         91         True         True     light rain  \n",
       "1     0      2.517241        102         True         True     light rain  \n",
       "2     0      2.517241        135         True         True    medium rain  \n",
       "3     0      2.517241         68         True         True     light rain  \n",
       "4     0      2.517241         75         True         True     light rain  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wind': PearsonRResult(statistic=np.float64(0.46885840130424355), pvalue=np.float64(0.007801325106885124)),\n",
       " 'T_ave': PearsonRResult(statistic=np.float64(0.018689634590047174), pvalue=np.float64(0.92050965152688)),\n",
       " 'T_low': PearsonRResult(statistic=np.float64(-0.1398856147873425), pvalue=np.float64(0.452926005345689)),\n",
       " 'T_high': PearsonRResult(statistic=np.float64(0.2008689996727488), pvalue=np.float64(0.27857643770101326)),\n",
       " 'sun': PearsonRResult(statistic=np.float64(-0.05774091178817214), pvalue=np.float64(0.7576760443316947)),\n",
       " 'rain_duration': PearsonRResult(statistic=np.float64(0.5922943256638151), pvalue=np.float64(0.0004475042650265651)),\n",
       " 'rain(mm)': PearsonRResult(statistic=np.float64(0.8131975402346316), pvalue=np.float64(2.7063566390647817e-08)),\n",
       " 'snow': PearsonRResult(statistic=np.float64(-0.05551868991960596), pvalue=np.float64(0.7667406451549881))}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {c: my_correlation(df[c], df[\"accidents\"]) for c in df.columns if c not in [\"accidents\", \"YYYYMMDD\", \"index\", \"rain_intensity\", \"fog_morning\", \"fog_evening\", \"weather alarm\"]}\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 34:** create a dictionary similar to that of the previous exercise, but now only for correlations whose p-value is below 0.05. (Hint: apply a filtering using an `if` statement in the dictionary comprehension.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wind': PearsonRResult(statistic=np.float64(0.46885840130424355), pvalue=np.float64(0.007801325106885124)),\n",
       " 'rain_duration': PearsonRResult(statistic=np.float64(0.5922943256638151), pvalue=np.float64(0.0004475042650265651)),\n",
       " 'rain(mm)': PearsonRResult(statistic=np.float64(0.8131975402346316), pvalue=np.float64(2.7063566390647817e-08))}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dic = {k: v for k, v in dic.items() if v[1] < 0.05}\n",
    "filtered_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data aggregation and group operations\n",
    "\n",
    "Most of the material of this part is derived from sections 8.3, 10.1 and 10.2 of McKinney."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** creating a DataFrame whose row and column indices are both of MultiIndex type. Both indices have two levels. For exercises 1-6, always start working with the original DataFrame `frame` and do not redefine this variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Alabama</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2017</th>\n",
       "      <th>spring</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>spring</th>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state           Ohio      Colorado Alabama     \n",
       "gender        female male   female  female male\n",
       "year semester                                  \n",
       "2017 spring       73   18       10      56   57\n",
       "     fall         45   75        8      63   74\n",
       "2018 spring       62   75        5      72   79\n",
       "     fall         13   86       53      27   89"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.random.randint(100, size=(4,5)),\n",
    "                     index=[[2017, 2017, 2018, 2018], ['spring', 'fall', 'spring', 'fall']],\n",
    "                     columns=[['Ohio', 'Ohio', 'Colorado', 'Alabama', 'Alabama'],\n",
    "                              ['female', 'male', 'female', 'female', 'male']])\n",
    "\n",
    "frame.index.names = ['year', 'semester']\n",
    "frame.columns.names = ['state', 'gender']\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** selecting the columns whose level-0 index is 'Ohio'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2017</th>\n",
       "      <th>spring</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>spring</th>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender         female  male\n",
       "year semester              \n",
       "2017 spring        73    18\n",
       "     fall          45    75\n",
       "2018 spring        62    75\n",
       "     fall          13    86"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['Ohio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** selecting the entries associated with 'Ohio' (level 0) and 'male' (level 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year  semester\n",
       "2017  spring      18\n",
       "      fall        75\n",
       "2018  spring      75\n",
       "      fall        86\n",
       "Name: (Ohio, male), dtype: int32"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['Ohio','male']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 35:** use `loc` to create a DataFrame with only the rows whose year is 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Alabama</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state      Ohio      Colorado Alabama     \n",
       "gender   female male   female  female male\n",
       "semester                                  \n",
       "spring       73   18       10      56   57\n",
       "fall         45   75        8      63   74"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.loc[2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 36:** use `loc` to create a Series with only the row whose year is 2017 and semester is fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state     gender\n",
       "Ohio      female    45\n",
       "          male      75\n",
       "Colorado  female     8\n",
       "Alabama   female    63\n",
       "          male      74\n",
       "Name: (2017, fall), dtype: int32"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.loc[2017, \"fall\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 37:** use `iloc` to create a Series with only the row whose year is 2018 and semester is fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state     gender\n",
       "Ohio      female    13\n",
       "          male      86\n",
       "Colorado  female    53\n",
       "Alabama   female    27\n",
       "          male      89\n",
       "Name: (2018, fall), dtype: int32"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** sorting the columns alphabetically for the 'state' part of the MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Alabama</th>\n",
       "      <th>Colorado</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2017</th>\n",
       "      <th>spring</th>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>spring</th>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state         Alabama      Colorado   Ohio     \n",
       "gender         female male   female female male\n",
       "year semester                                  \n",
       "2017 spring        56   57       10     73   18\n",
       "     fall          63   74        8     45   75\n",
       "2018 spring        72   79        5     62   75\n",
       "     fall          27   89       53     13   86"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.sort_index(level='state', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** swapping the levels of the row MultiIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Alabama</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semester</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <th>2017</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <th>2017</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spring</th>\n",
       "      <th>2018</th>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <th>2018</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state           Ohio      Colorado Alabama     \n",
       "gender        female male   female  female male\n",
       "semester year                                  \n",
       "spring   2017     73   18       10      56   57\n",
       "fall     2017     45   75        8      63   74\n",
       "spring   2018     62   75        5      72   79\n",
       "fall     2018     13   86       53      27   89"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.swaplevel('year', 'semester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 38:** swap the levels of the column MultiIndex of `frame` and sort its rows by semester, in reverse alphabetical order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Ohio</th>\n",
       "      <th>Colorado</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Alabama</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <th>spring</th>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <th>spring</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <th>fall</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <th>fall</th>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>63</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "state           Ohio      Colorado Alabama     \n",
       "gender        female male   female  female male\n",
       "year semester                                  \n",
       "2018 spring       62   75        5      72   79\n",
       "2017 spring       73   18       10      56   57\n",
       "2018 fall         13   86       53      27   89\n",
       "2017 fall         45   75        8      63   74"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.sort_index(level='semester', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** aggregating the data for the different states by summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() got an unexpected keyword argument 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:11670\u001b[0m, in \u001b[0;36mDataFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11661\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  11663\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11668\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11669\u001b[0m ):\n\u001b[1;32m> 11670\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12506\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[1;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  12499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12500\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12505\u001b[0m ):\n\u001b[1;32m> 12506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_count_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12507\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  12508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12471\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  12459\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  12460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_min_count_stat_function\u001b[39m(\n\u001b[0;32m  12461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12468\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12469\u001b[0m ):\n\u001b[0;32m  12470\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\n\u001b[1;32m> 12471\u001b[0m     \u001b[43mnv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  12473\u001b[0m     validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m  12475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\compat\\numpy\\function.py:418\u001b[0m, in \u001b[0;36mvalidate_func\u001b[1;34m(fname, args, kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_stat_func(args, kwargs, fname\u001b[38;5;241m=\u001b[39mfname)\n\u001b[0;32m    417\u001b[0m validation_func \u001b[38;5;241m=\u001b[39m _validation_funcs[fname]\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidation_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\compat\\numpy\\function.py:88\u001b[0m, in \u001b[0;36mCompatValidator.__call__\u001b[1;34m(self, args, kwargs, fname, max_fname_arg_count, method)\u001b[0m\n\u001b[0;32m     86\u001b[0m     validate_kwargs(fname, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[43mvalidate_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fname_arg_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefaults\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid validation method \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\util\\_validators.py:223\u001b[0m, in \u001b[0;36mvalidate_args_and_kwargs\u001b[1;34m(fname, args, kwargs, max_fname_arg_count, compat_args)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         )\n\u001b[0;32m    222\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(args_dict)\n\u001b[1;32m--> 223\u001b[0m \u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\util\\_validators.py:164\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[1;34m(fname, kwargs, compat_args)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03mChecks whether parameters passed to the **kwargs argument in a\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03mfunction `fname` are valid parameters as specified in `*compat_args`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03mmap to the default values specified in `compat_args`\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m kwds \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 164\u001b[0m \u001b[43m_check_for_invalid_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m _check_for_default_values(fname, kwds, compat_args)\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\util\\_validators.py:138\u001b[0m, in \u001b[0;36m_check_for_invalid_keys\u001b[1;34m(fname, kwargs, compat_args)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m    137\u001b[0m     bad_arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(diff))\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sum() got an unexpected keyword argument 'level'"
     ]
    }
   ],
   "source": [
    "frame.sum(level='gender', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 39:** calculate the mean quantities of `frame` for each combination of year and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mb:\\Documents\\Skola\\UvA\\Y4P1\\Data Science Methodology\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state'"
     ]
    }
   ],
   "source": [
    "fram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 40:** use `stack` and `unstack` to turn the row index 'year' into a column index and the column index 'gender' into a row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** transforming the data of `frame` into a new `DataFrame` without MultiIndex. We call the new DataFrame `frame2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = frame.stack().stack().reset_index().rename({0 : 'quantity'}, axis=1)\n",
    "frame2.quantity = frame2.quantity.astype(int)\n",
    "\n",
    "frame2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** using `groupby` to compute the mean quantity per gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.groupby('gender').mean().quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** we have already seen how to use `frame` to calculate the minimum quantity for each combination of year and state. This is done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame.min(level='year').min(level='state', axis=1).sort_index(level=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 41:** apply `groupby` to `frame2` to reproduce the DataFrame of the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
