{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "**Deadline**:  18/10/2021, 17:00\n",
    "\n",
    "**Names and student numbers:**\n",
    "1. name (student number)\n",
    "2. ...\n",
    "3. ...\n",
    "\n",
    "**Declaration of Originality**\n",
    "\n",
    "We whose names are given under 1., 2. and 3. above declare that:\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made (part of) these solutions available to any other student.\n",
    "\n",
    "## Instructions for completing and submitting the assignment\n",
    "Please pay attention to the following instructions:\n",
    "1. Please follow carefully the steps outlined in the assignment. If you cannot solve an exercise and this hinders continuing with subsequent exercises, try to find a way to work around it and give a clear explanation for the solution you have chosen.\n",
    "2. Submit your work in the form of a Jupyter notebook via Canvas, before the deadline. Your notebook should not give errors when executed with `Run All`.\n",
    "4. You are allowed to work on the assignment in groups of 2 or 3 students and to submit together. Before you submit, you and your team members have to register as an **Assignment group** on Canvas. Only a single member of each group has to submit the notebook. Please do **NOT** submit the same notebook multiple times!\n",
    "5. Please write your names also inside this markdown cell, under **Names and student numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "In this assignment you have to develop a regression model. You will be given a training set of 800 datapoints. Using the techniques presented in this course, we ask you to come up with a model that has the best generalization performance. This performance will be assessed on a test dataset of 16,000 datapoints, which is not available to you. The assignment is also a competition: your mark depends (partly) on how well your model does compared to those of other groups and the three groups with the best performing model will be announced on Canvas.\n",
    "\n",
    "### The data\n",
    "The training data can be found in the file “training_data.csv” on Canvas. It consists of a two-dimensional comma-separated matrix of 800 rows and 27 columns. Each row is a datapoint, consisting of 26 input variables and 1 target variable. The target variable is the last column of the matrix.\n",
    "\n",
    "### Submitting your work\n",
    "Your work in this Jupyter notebook consists of two parts. **Part 1** is used to train, create and evaluate your best performing model. In the first cell, you have to train your best performing model on the training data. The code to load the training data is already given. Furthermore, in that same cell you have to create a function called `best_model`. This function has a single input argument, which is a 2-dimensional NumPy array with an arbitrary number of rows and 26 columns (e.g. the input features `X` of the training data). The function should return a 1-dimensional array with the predictions of your best model for the datapoints in the input argument. Hence, the number of elements in this 1-dimensional array should be equal to the number of rows of the 2-dimensional array used as input argument.\n",
    "\n",
    "In the second cell, we are using a testset called `test_data.csv` of 16,000 datapoints to assess the generalization performance of your function `best_model`. Of course, the testset is only available to the teachers. The code in the second cell may not be changed!!! It will be used by the teachers to compute the generalization performance of your best model. On Canvas, you can find a file called `FAKE_test_data.csv`. This is a 2-dimensional array of completely random numbers (fake data), having the same dimensions as the dataset in `test_data.csv`. If you put this file in the same folder as this Jupyter notebook, you can test whether your function `best_model` is defined correctly by checking if the second cell runs without errors. Since the numbers in `FAKE_test_data.csv` are fake data, they **cannot** be used to estimate the performance of your `best_model`. **AFTER TRAINING AND CREATING YOUR BEST MODEL IN THE FIRST CELL, THE SECOND CELL SHOULD RUN WITHOUT ERRORS!!!** If this is not the case, your work will **not** be marked. \n",
    "\n",
    "In **Part 2** of the notebook, you will present your analysis of the regression problem and the steps you have taken to arrive at your best model. Here, you have to explain and perform all the methods that you have used to identify your best model. As in all exercises, please make sure all steps are well motivated and presented in a clear and structured manner. We recommend using visualization methods (e.g., plots with matplotlib), if applicable, to clarify your work.\n",
    "\n",
    "### Examples\n",
    "On Canvas, you can find two example notebooks (“DSM_assignment3_example_with_sklearn.ipynb”, “DSM_assignment3_example_without_sklearn.ipynb”). These notebooks contain examples of how you can submit **Part 1** of the assignment. As \"best model\" in the examples, we have **arbitrarily** chosen for a regression model using the third power of the 7-th principal component. In one of the files we use scikit-learn, whereas in the other one we train the same model without using scikit-learn. Please look carefully at how the function `best_model` is created and make sure you understand all steps.\n",
    "\n",
    "### Allowed methods\n",
    "Any of the methods discussed in the course may be used. You are also allowed to combine different models and techniques. If you doubt whether your method is allowed, please consult with the teachers. \n",
    "\n",
    "Furthermore, you are allowed to use libraries like scikit-learn, but you are not required to use them.\n",
    "\n",
    "### The competition\n",
    "The generalization performance of your best model is assessed by the **root mean squared error (RMSE)** on a secret test dataset consisting of 16,000 independent and identically distributed datapoints. They were created with the same data-generating process as the data of the training set of 800 datapoints. The scores will be ranked and the top-three groups and their scores will be announced in class.\n",
    "\n",
    "### The marking\n",
    "As can be seen in the rubric on Canvas, 20% of your mark will depend on the generalization performance of your best model, compared to the best models of your peers. The other 80% is for the quality of your analysis and your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: training, creating and evaluating your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# USE THIS CELL TO TRAIN AND CREATE YOUR BEST MODEL # \n",
    "#####################################################\n",
    "\n",
    "# loading the training data\n",
    "training_data = np.genfromtxt(\"training_data.csv\", delimiter=',')\n",
    "X = training_data[:,:-1]\n",
    "y = training_data[:,-1]\n",
    "\n",
    "# X = X[abs(y) < 2 * np.std(y) + np.mean(y)]\n",
    "# y = y[abs(y) < 2 * np.std(y) + np.mean(y)]\n",
    "\n",
    "# determining the principal components using SVD\n",
    "U, D, V_T = np.linalg.svd(X, full_matrices=False)\n",
    "V = V_T.T\n",
    "Z = X @ V\n",
    "\n",
    "# training the best model\n",
    "model = LinearRegression()\n",
    "model.fit(Z[:,6:7]**3, y)\n",
    "\n",
    "# creating the predictive function best_model()\n",
    "def best_model(X_new):\n",
    "    \n",
    "    Z_new = X_new @ V      # projecting new observations on principal components directions\n",
    "    features_new = Z_new[:,6:7]**3     # selecting the feature(s) used in the model\n",
    "    predictions = model.predict(features_new)          # making predictions\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(64.17908187101574)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = best_model(X)\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE is:  1.8456462073870714\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#    !!!DO NOT CHANGE THE CODE IN THIS CELL!!!       #\n",
    "# THIS CELL IS USED FOR EVALUATING YOUR BEST MODEL.  #  \n",
    "# AFTER TRAINING AND CREATING YOUR BEST MODEL IN THE #\n",
    "# PREVIOUS CELL, THIS CELL SHOULD RUN WITHOUT ERRORS # \n",
    "######################################################\n",
    "\n",
    "# Determining which test data will be used. If real test \n",
    "# data is available, it will be used. Otherwise, the \n",
    "# fake test data will be used.\n",
    "if os.path.exists(\"test_data.csv\"):\n",
    "    test_data_filename = \"test_data.csv\"\n",
    "elif os.path.exists(\"FAKE_test_data.csv\"):\n",
    "    test_data_filename = \"FAKE_test_data.csv\"\n",
    "else:\n",
    "    test_data_filename = None\n",
    "    print(\"ERROR: Test data is missing!\")\n",
    "    \n",
    "if test_data_filename:\n",
    "\n",
    "    # loading the test data    \n",
    "    test_data = np.genfromtxt(test_data_filename, delimiter=',')\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,-1]\n",
    "\n",
    "    # making predictions and computing the root mean squared error (RMSE)\n",
    "    predictions = best_model(X_test)\n",
    "    RMSE = np.sqrt(np.mean((predictions - y_test)**2))\n",
    "\n",
    "    print(\"The RMSE is: \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
